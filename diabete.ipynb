{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002df6d7-1db8-46b8-943b-51d79baac1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d9e1a4c-d411-4520-bf13-8bb051bdf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/home/texturelab/Desktop/mrinmoy projects/pytorch/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8eafa67-ed60-437c-8492-10a3ab01624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Triceps skin fold thickness</th>\n",
       "      <th>2-Hour serum insulin</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>50</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>31</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>32</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>21</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>33</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>63</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>27</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>30</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>47</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>23</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of times pregnant  Plasma glucose concentration  \\\n",
       "0                           6                           148   \n",
       "1                           1                            85   \n",
       "2                           8                           183   \n",
       "3                           1                            89   \n",
       "4                           0                           137   \n",
       "..                        ...                           ...   \n",
       "763                        10                           101   \n",
       "764                         2                           122   \n",
       "765                         5                           121   \n",
       "766                         1                           126   \n",
       "767                         1                            93   \n",
       "\n",
       "     Diastolic blood pressure  Triceps skin fold thickness  \\\n",
       "0                          72                           35   \n",
       "1                          66                           29   \n",
       "2                          64                            0   \n",
       "3                          66                           23   \n",
       "4                          40                           35   \n",
       "..                        ...                          ...   \n",
       "763                        76                           48   \n",
       "764                        70                           27   \n",
       "765                        72                           23   \n",
       "766                        60                            0   \n",
       "767                        70                           31   \n",
       "\n",
       "     2-Hour serum insulin  Body mass index  Age     Class  \n",
       "0                       0             33.6   50  positive  \n",
       "1                       0             26.6   31  negative  \n",
       "2                       0             23.3   32  positive  \n",
       "3                      94             28.1   21  negative  \n",
       "4                     168             43.1   33  positive  \n",
       "..                    ...              ...  ...       ...  \n",
       "763                   180             32.9   63  negative  \n",
       "764                     0             36.8   27  negative  \n",
       "765                   112             26.2   30  negative  \n",
       "766                     0             30.1   47  positive  \n",
       "767                     0             30.4   23  negative  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7455c7-e743-4681-ac85-af24f17875fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data.iloc[:,0:-1].values\n",
    "y_string=list(data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676e9e4f-8313-4d17-99ad-3a5137c616c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce424be4-9d60-4475-ae20-6eb405f1037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_int=[]\n",
    "for s in y_string:\n",
    "    if s=='positive':\n",
    "        y_int.append(1)\n",
    "    else:\n",
    "        y_int.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496cb0fe-cf61-43cf-b18b-372874c74653",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y_int,dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b8371ed-d75d-4733-8aa9-b43150d58d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6. , 148. ,  72. , ...,   0. ,  33.6,  50. ],\n",
       "       [  1. ,  85. ,  66. , ...,   0. ,  26.6,  31. ],\n",
       "       [  8. , 183. ,  64. , ...,   0. ,  23.3,  32. ],\n",
       "       ...,\n",
       "       [  5. , 121. ,  72. , ..., 112. ,  26.2,  30. ],\n",
       "       [  1. , 126. ,  60. , ...,   0. ,  30.1,  47. ],\n",
       "       [  1. ,  93. ,  70. , ...,   0. ,  30.4,  23. ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9299132c-f33e-4d5e-8190-8071f5e97add",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc= StandardScaler()\n",
    "x=sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370410d0-a9af-44d0-b253-0d8a8c63a860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.84832379,  0.14964075, ..., -0.69289057,\n",
       "         0.20401277,  1.4259954 ],\n",
       "       [-0.84488505, -1.12339636, -0.16054575, ..., -0.69289057,\n",
       "        -0.68442195, -0.19067191],\n",
       "       [ 1.23388019,  1.94372388, -0.26394125, ..., -0.69289057,\n",
       "        -1.10325546, -0.10558415],\n",
       "       ...,\n",
       "       [ 0.3429808 ,  0.00330087,  0.14964075, ...,  0.27959377,\n",
       "        -0.73518964, -0.27575966],\n",
       "       [-0.84488505,  0.1597866 , -0.47073225, ..., -0.69289057,\n",
       "        -0.24020459,  1.17073215],\n",
       "       [-0.84488505, -0.8730192 ,  0.04624525, ..., -0.69289057,\n",
       "        -0.20212881, -0.87137393]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca72feb8-9f29-44c2-8ba6-582a07cde840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the arrays to pytorch tensor\n",
    "x=torch.tensor(x)\n",
    "y=torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc76004c-f20c-4244-9dba-ba7b7af141df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a55a563b-34d1-4df9-8965-8a245c54f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf614665-7c26-4b8b-8351-5e11bc29a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 7])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "603eca31-96e2-4a67-8086-75a80cbba55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40d3cdc8-1de9-4d7f-8c45-babea37c70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7d97c46-579a-4156-8922-5e4e3b62d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=Dataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2179651d-f6b4-4c83-a7c7-a87cf13497b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ab98915-9e92-49d6-8c82-427d01e58808",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=dataset,\n",
    "                            batch_size=32,\n",
    "                            shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6397438-9a70-4e58-a2f0-5b374b2f40c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 24 batches in the dataset\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n",
      "for one iteration, there is:\n",
      "Data:   torch.Size([32, 7])\n",
      "labels: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"There is {} batches in the dataset\".format(len(train_loader)))\n",
    "for(x,y) in train_loader:\n",
    "    print(\"for one iteration, there is:\")\n",
    "    print(\"Data:   {}\".format(x.shape))\n",
    "    print(\"labels: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6e5c5da-11cb-41b1-af93-b8358489c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(Model,self).__init__()\n",
    "        self.fc1= nn.Linear(input_features,5)\n",
    "        self.fc2 = nn.Linear(5,4)\n",
    "        self.fc3=nn.Linear(4,3)\n",
    "        self.fc4=nn.Linear(3,output_features)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.tanh=nn.Tanh()\n",
    "    def forward(self,x):\n",
    "        out= self.fc1(x)\n",
    "        out=self.tanh(out)\n",
    "        out= self.fc2(out)\n",
    "        out=self.tanh(out)\n",
    "        out= self.fc3(out)\n",
    "        out=self.tanh(out)\n",
    "        out= self.fc4(out)\n",
    "        out=self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ac63c63-4a7d-4d94-bba6-911b6b5d336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net= Model(7,1)\n",
    "\n",
    "criterion= torch.nn.BCELoss(size_average=True)\n",
    "\n",
    "optimizer=torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34204979-e736-4392-bdfb-2487ed8e29ef",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b151d2-2e74-4e43-bf7d-d9b6bc9c6f6d",
   "metadata": {},
   "source": [
    "### Evalution metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2719b4f0-1933-4e13-9d7c-312f3052f8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1/200, loss: 0.410, Accuracy: 0.719\n",
      "Epoch2/200, loss: 0.472, Accuracy: 0.844\n",
      "Epoch3/200, loss: 0.443, Accuracy: 0.844\n",
      "Epoch4/200, loss: 0.486, Accuracy: 0.719\n",
      "Epoch5/200, loss: 0.422, Accuracy: 0.781\n",
      "Epoch6/200, loss: 0.495, Accuracy: 0.781\n",
      "Epoch7/200, loss: 0.449, Accuracy: 0.844\n",
      "Epoch8/200, loss: 0.377, Accuracy: 0.719\n",
      "Epoch9/200, loss: 0.261, Accuracy: 0.875\n",
      "Epoch10/200, loss: 0.425, Accuracy: 0.719\n",
      "Epoch11/200, loss: 0.441, Accuracy: 0.781\n",
      "Epoch12/200, loss: 0.307, Accuracy: 0.844\n",
      "Epoch13/200, loss: 0.373, Accuracy: 0.812\n",
      "Epoch14/200, loss: 0.451, Accuracy: 0.750\n",
      "Epoch15/200, loss: 0.370, Accuracy: 0.938\n",
      "Epoch16/200, loss: 0.431, Accuracy: 0.688\n",
      "Epoch17/200, loss: 0.314, Accuracy: 0.875\n",
      "Epoch18/200, loss: 0.325, Accuracy: 0.812\n",
      "Epoch19/200, loss: 0.386, Accuracy: 0.781\n",
      "Epoch20/200, loss: 0.429, Accuracy: 0.781\n",
      "Epoch21/200, loss: 0.460, Accuracy: 0.719\n",
      "Epoch22/200, loss: 0.258, Accuracy: 0.906\n",
      "Epoch23/200, loss: 0.316, Accuracy: 0.844\n",
      "Epoch24/200, loss: 0.303, Accuracy: 0.844\n",
      "Epoch25/200, loss: 0.592, Accuracy: 0.625\n",
      "Epoch26/200, loss: 0.439, Accuracy: 0.812\n",
      "Epoch27/200, loss: 0.348, Accuracy: 0.844\n",
      "Epoch28/200, loss: 0.587, Accuracy: 0.656\n",
      "Epoch29/200, loss: 0.451, Accuracy: 0.688\n",
      "Epoch30/200, loss: 0.337, Accuracy: 0.844\n",
      "Epoch31/200, loss: 0.365, Accuracy: 0.781\n",
      "Epoch32/200, loss: 0.643, Accuracy: 0.625\n",
      "Epoch33/200, loss: 0.697, Accuracy: 0.656\n",
      "Epoch34/200, loss: 0.359, Accuracy: 0.906\n",
      "Epoch35/200, loss: 0.347, Accuracy: 0.875\n",
      "Epoch36/200, loss: 0.320, Accuracy: 0.906\n",
      "Epoch37/200, loss: 0.422, Accuracy: 0.844\n",
      "Epoch38/200, loss: 0.337, Accuracy: 0.750\n",
      "Epoch39/200, loss: 0.480, Accuracy: 0.781\n",
      "Epoch40/200, loss: 0.284, Accuracy: 0.938\n",
      "Epoch41/200, loss: 0.371, Accuracy: 0.781\n",
      "Epoch42/200, loss: 0.394, Accuracy: 0.812\n",
      "Epoch43/200, loss: 0.377, Accuracy: 0.844\n",
      "Epoch44/200, loss: 0.708, Accuracy: 0.750\n",
      "Epoch45/200, loss: 0.361, Accuracy: 0.781\n",
      "Epoch46/200, loss: 0.286, Accuracy: 0.906\n",
      "Epoch47/200, loss: 0.238, Accuracy: 0.812\n",
      "Epoch48/200, loss: 0.394, Accuracy: 0.844\n",
      "Epoch49/200, loss: 0.439, Accuracy: 0.812\n",
      "Epoch50/200, loss: 0.516, Accuracy: 0.719\n",
      "Epoch51/200, loss: 0.351, Accuracy: 0.781\n",
      "Epoch52/200, loss: 0.386, Accuracy: 0.812\n",
      "Epoch53/200, loss: 0.496, Accuracy: 0.656\n",
      "Epoch54/200, loss: 0.366, Accuracy: 0.844\n",
      "Epoch55/200, loss: 0.404, Accuracy: 0.875\n",
      "Epoch56/200, loss: 0.220, Accuracy: 0.969\n",
      "Epoch57/200, loss: 0.536, Accuracy: 0.656\n",
      "Epoch58/200, loss: 0.404, Accuracy: 0.781\n",
      "Epoch59/200, loss: 0.588, Accuracy: 0.688\n",
      "Epoch60/200, loss: 0.546, Accuracy: 0.750\n",
      "Epoch61/200, loss: 0.360, Accuracy: 0.844\n",
      "Epoch62/200, loss: 0.215, Accuracy: 0.969\n",
      "Epoch63/200, loss: 0.350, Accuracy: 0.812\n",
      "Epoch64/200, loss: 0.584, Accuracy: 0.812\n",
      "Epoch65/200, loss: 0.405, Accuracy: 0.781\n",
      "Epoch66/200, loss: 0.651, Accuracy: 0.688\n",
      "Epoch67/200, loss: 0.350, Accuracy: 0.812\n",
      "Epoch68/200, loss: 0.398, Accuracy: 0.812\n",
      "Epoch69/200, loss: 0.385, Accuracy: 0.688\n",
      "Epoch70/200, loss: 0.445, Accuracy: 0.781\n",
      "Epoch71/200, loss: 0.359, Accuracy: 0.750\n",
      "Epoch72/200, loss: 0.352, Accuracy: 0.844\n",
      "Epoch73/200, loss: 0.470, Accuracy: 0.781\n",
      "Epoch74/200, loss: 0.640, Accuracy: 0.625\n",
      "Epoch75/200, loss: 0.306, Accuracy: 0.906\n",
      "Epoch76/200, loss: 0.511, Accuracy: 0.625\n",
      "Epoch77/200, loss: 0.278, Accuracy: 0.812\n",
      "Epoch78/200, loss: 0.448, Accuracy: 0.719\n",
      "Epoch79/200, loss: 0.316, Accuracy: 0.844\n",
      "Epoch80/200, loss: 0.356, Accuracy: 0.812\n",
      "Epoch81/200, loss: 0.574, Accuracy: 0.781\n",
      "Epoch82/200, loss: 0.315, Accuracy: 0.875\n",
      "Epoch83/200, loss: 0.415, Accuracy: 0.781\n",
      "Epoch84/200, loss: 0.301, Accuracy: 0.875\n",
      "Epoch85/200, loss: 0.271, Accuracy: 0.812\n",
      "Epoch86/200, loss: 0.401, Accuracy: 0.812\n",
      "Epoch87/200, loss: 0.438, Accuracy: 0.812\n",
      "Epoch88/200, loss: 0.534, Accuracy: 0.688\n",
      "Epoch89/200, loss: 0.366, Accuracy: 0.812\n",
      "Epoch90/200, loss: 0.261, Accuracy: 0.906\n",
      "Epoch91/200, loss: 0.385, Accuracy: 0.750\n",
      "Epoch92/200, loss: 0.515, Accuracy: 0.781\n",
      "Epoch93/200, loss: 0.431, Accuracy: 0.750\n",
      "Epoch94/200, loss: 0.246, Accuracy: 0.875\n",
      "Epoch95/200, loss: 0.397, Accuracy: 0.750\n",
      "Epoch96/200, loss: 0.378, Accuracy: 0.719\n",
      "Epoch97/200, loss: 0.421, Accuracy: 0.812\n",
      "Epoch98/200, loss: 0.284, Accuracy: 0.844\n",
      "Epoch99/200, loss: 0.314, Accuracy: 0.844\n",
      "Epoch100/200, loss: 0.429, Accuracy: 0.812\n",
      "Epoch101/200, loss: 0.578, Accuracy: 0.781\n",
      "Epoch102/200, loss: 0.461, Accuracy: 0.781\n",
      "Epoch103/200, loss: 0.344, Accuracy: 0.844\n",
      "Epoch104/200, loss: 0.315, Accuracy: 0.875\n",
      "Epoch105/200, loss: 0.413, Accuracy: 0.844\n",
      "Epoch106/200, loss: 0.191, Accuracy: 0.938\n",
      "Epoch107/200, loss: 0.353, Accuracy: 0.812\n",
      "Epoch108/200, loss: 0.502, Accuracy: 0.688\n",
      "Epoch109/200, loss: 0.390, Accuracy: 0.781\n",
      "Epoch110/200, loss: 0.506, Accuracy: 0.781\n",
      "Epoch111/200, loss: 0.190, Accuracy: 0.906\n",
      "Epoch112/200, loss: 0.358, Accuracy: 0.875\n",
      "Epoch113/200, loss: 0.440, Accuracy: 0.812\n",
      "Epoch114/200, loss: 0.398, Accuracy: 0.875\n",
      "Epoch115/200, loss: 0.425, Accuracy: 0.719\n",
      "Epoch116/200, loss: 0.470, Accuracy: 0.812\n",
      "Epoch117/200, loss: 0.572, Accuracy: 0.719\n",
      "Epoch118/200, loss: 0.395, Accuracy: 0.781\n",
      "Epoch119/200, loss: 0.460, Accuracy: 0.812\n",
      "Epoch120/200, loss: 0.481, Accuracy: 0.812\n",
      "Epoch121/200, loss: 0.265, Accuracy: 0.875\n",
      "Epoch122/200, loss: 0.600, Accuracy: 0.719\n",
      "Epoch123/200, loss: 0.347, Accuracy: 0.875\n",
      "Epoch124/200, loss: 0.509, Accuracy: 0.656\n",
      "Epoch125/200, loss: 0.342, Accuracy: 0.844\n",
      "Epoch126/200, loss: 0.418, Accuracy: 0.750\n",
      "Epoch127/200, loss: 0.390, Accuracy: 0.781\n",
      "Epoch128/200, loss: 0.265, Accuracy: 0.875\n",
      "Epoch129/200, loss: 0.438, Accuracy: 0.750\n",
      "Epoch130/200, loss: 0.442, Accuracy: 0.781\n",
      "Epoch131/200, loss: 0.432, Accuracy: 0.719\n",
      "Epoch132/200, loss: 0.371, Accuracy: 0.750\n",
      "Epoch133/200, loss: 0.353, Accuracy: 0.844\n",
      "Epoch134/200, loss: 0.416, Accuracy: 0.781\n",
      "Epoch135/200, loss: 0.360, Accuracy: 0.812\n",
      "Epoch136/200, loss: 0.433, Accuracy: 0.812\n",
      "Epoch137/200, loss: 0.357, Accuracy: 0.781\n",
      "Epoch138/200, loss: 0.425, Accuracy: 0.781\n",
      "Epoch139/200, loss: 0.529, Accuracy: 0.688\n",
      "Epoch140/200, loss: 0.240, Accuracy: 0.875\n",
      "Epoch141/200, loss: 0.376, Accuracy: 0.781\n",
      "Epoch142/200, loss: 0.488, Accuracy: 0.688\n",
      "Epoch143/200, loss: 0.305, Accuracy: 0.875\n",
      "Epoch144/200, loss: 0.376, Accuracy: 0.688\n",
      "Epoch145/200, loss: 0.288, Accuracy: 0.906\n",
      "Epoch146/200, loss: 0.409, Accuracy: 0.750\n",
      "Epoch147/200, loss: 0.476, Accuracy: 0.812\n",
      "Epoch148/200, loss: 0.431, Accuracy: 0.844\n",
      "Epoch149/200, loss: 0.395, Accuracy: 0.844\n",
      "Epoch150/200, loss: 0.406, Accuracy: 0.750\n",
      "Epoch151/200, loss: 0.391, Accuracy: 0.906\n",
      "Epoch152/200, loss: 0.348, Accuracy: 0.812\n",
      "Epoch153/200, loss: 0.505, Accuracy: 0.781\n",
      "Epoch154/200, loss: 0.322, Accuracy: 0.844\n",
      "Epoch155/200, loss: 0.286, Accuracy: 0.812\n",
      "Epoch156/200, loss: 0.397, Accuracy: 0.781\n",
      "Epoch157/200, loss: 0.208, Accuracy: 0.938\n",
      "Epoch158/200, loss: 0.315, Accuracy: 0.875\n",
      "Epoch159/200, loss: 0.447, Accuracy: 0.750\n",
      "Epoch160/200, loss: 0.308, Accuracy: 0.906\n",
      "Epoch161/200, loss: 0.584, Accuracy: 0.750\n",
      "Epoch162/200, loss: 0.443, Accuracy: 0.812\n",
      "Epoch163/200, loss: 0.504, Accuracy: 0.719\n",
      "Epoch164/200, loss: 0.281, Accuracy: 0.844\n",
      "Epoch165/200, loss: 0.348, Accuracy: 0.781\n",
      "Epoch166/200, loss: 0.433, Accuracy: 0.719\n",
      "Epoch167/200, loss: 0.314, Accuracy: 0.812\n",
      "Epoch168/200, loss: 0.444, Accuracy: 0.781\n",
      "Epoch169/200, loss: 0.357, Accuracy: 0.781\n",
      "Epoch170/200, loss: 0.440, Accuracy: 0.812\n",
      "Epoch171/200, loss: 0.331, Accuracy: 0.844\n",
      "Epoch172/200, loss: 0.492, Accuracy: 0.656\n",
      "Epoch173/200, loss: 0.396, Accuracy: 0.844\n",
      "Epoch174/200, loss: 0.434, Accuracy: 0.688\n",
      "Epoch175/200, loss: 0.364, Accuracy: 0.875\n",
      "Epoch176/200, loss: 0.469, Accuracy: 0.688\n",
      "Epoch177/200, loss: 0.418, Accuracy: 0.719\n",
      "Epoch178/200, loss: 0.358, Accuracy: 0.750\n",
      "Epoch179/200, loss: 0.633, Accuracy: 0.625\n",
      "Epoch180/200, loss: 0.314, Accuracy: 0.844\n",
      "Epoch181/200, loss: 0.384, Accuracy: 0.781\n",
      "Epoch182/200, loss: 0.292, Accuracy: 0.844\n",
      "Epoch183/200, loss: 0.418, Accuracy: 0.781\n",
      "Epoch184/200, loss: 0.361, Accuracy: 0.875\n",
      "Epoch185/200, loss: 0.435, Accuracy: 0.781\n",
      "Epoch186/200, loss: 0.416, Accuracy: 0.656\n",
      "Epoch187/200, loss: 0.412, Accuracy: 0.781\n",
      "Epoch188/200, loss: 0.454, Accuracy: 0.812\n",
      "Epoch189/200, loss: 0.429, Accuracy: 0.719\n",
      "Epoch190/200, loss: 0.365, Accuracy: 0.875\n",
      "Epoch191/200, loss: 0.381, Accuracy: 0.781\n",
      "Epoch192/200, loss: 0.518, Accuracy: 0.719\n",
      "Epoch193/200, loss: 0.399, Accuracy: 0.844\n",
      "Epoch194/200, loss: 0.219, Accuracy: 0.938\n",
      "Epoch195/200, loss: 0.364, Accuracy: 0.844\n",
      "Epoch196/200, loss: 0.266, Accuracy: 0.812\n",
      "Epoch197/200, loss: 0.477, Accuracy: 0.781\n",
      "Epoch198/200, loss: 0.414, Accuracy: 0.719\n",
      "Epoch199/200, loss: 0.339, Accuracy: 0.875\n",
      "Epoch200/200, loss: 0.392, Accuracy: 0.812\n"
     ]
    }
   ],
   "source": [
    "epochs= 200\n",
    "for epoch in range(200):\n",
    "    for inputs, labels in train_loader: \n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        # forward prop\n",
    "        outputs = net(inputs)\n",
    "        #loss calculation\n",
    "        loss= criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        #backprop\n",
    "        loss.backward()\n",
    "        #update weights\n",
    "        optimizer.step()\n",
    "    #accuracy calculation\n",
    "    output= (outputs>0.5).float()\n",
    "    accuracy = (output== labels).float().mean()\n",
    "    print(\"Epoch{}/{}, loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1, epochs, loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de0c0a-6f46-4da8-a4fb-71754aa8edf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2229f-9e28-4f4e-9746-9435fe350168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
